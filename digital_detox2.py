# -*- coding: utf-8 -*-
"""digital_detox.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ea2LJBUeb0pGJMCCj6rGPx6Ua4eGHZ4M
"""

# import numpy as np
# import pandas as pd
# import matplotlib.pyplot as plt
# from datetime import datetime, timedelta
# from sklearn.preprocessing import StandardScaler
# from sklearn.cluster import KMeans
# import seaborn as sns

# # Function to generate synthetic data
# def generate_synthetic_data(days=30, users=100):
#     np.random.seed(42)
#     data = []
#     for user in range(users):
#         start_date = datetime.now() - timedelta(days=days)
#         for day in range(days):
#             date = start_date + timedelta(days=day)
#             screen_time = np.random.normal(300, 50)  # in minutes
#             notifications = np.random.poisson(50)
#             app_usage = {f"app_{i}": np.random.normal(30, 10) for i in range(1, 6)}  # in minutes
#             data.append([user, date, screen_time, notifications] + list(app_usage.values()))

#     columns = ['user_id', 'date', 'screen_time', 'notifications'] + [f'app_{i}_usage' for i in range(1, 6)]
#     df = pd.DataFrame(data, columns=columns)
#     return df

# # Generate the data
# df = generate_synthetic_data()
# print(df.head())

# # Data Preprocessing
# # Handle missing values
# df.fillna(df.mean(), inplace=True)

# # Normalize the data
# scaler = StandardScaler()
# df[['screen_time', 'notifications'] + [f'app_{i}_usage' for i in range(1, 6)]] = scaler.fit_transform(
#     df[['screen_time', 'notifications'] + [f'app_{i}_usage' for i in range(1, 6)]]
# )

# print(df.head())

# # Feature Engineering
# df['day_of_week'] = df['date'].dt.dayofweek
# df['weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)

# print(df.head())

# # Model Building and Training
# # Select features for clustering
# features = ['screen_time', 'notifications'] + [f'app_{i}_usage' for i in range(1, 6)] + ['day_of_week', 'weekend']

# # Train the model
# kmeans = KMeans(n_clusters=3, random_state=42)
# df['attention_cluster'] = kmeans.fit_predict(df[features])

# print(df['attention_cluster'].value_counts())

# # Dashboard and Insights Visualization
# # Visualize the clusters
# plt.figure(figsize=(10, 6))
# sns.scatterplot(x='screen_time', y='notifications', hue='attention_cluster', data=df, palette='viridis')
# plt.title('Attention Clusters')
# plt.show()

# # Recommendations
# def generate_recommendations(cluster):
#     if cluster == 0:
#         return "Consider reducing screen time during peak focus hours."
#     elif cluster == 1:
#         return "Try limiting notifications to improve focus."
#     elif cluster == 2:
#         return "Great focus! Maintain your current habits."
#     else:
#         return "Monitor your app usage and adjust accordingly."

# df['recommendations'] = df['attention_cluster'].apply(generate_recommendations)
# print(df[['user_id', 'attention_cluster', 'recommendations']].head())

"""Data Collection and Synthetic Data Generation"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import seaborn as sns

# Function to generate synthetic data with more details
def generate_detailed_synthetic_data(days=30, users=100):
    np.random.seed(42)
    data = []
    for user in range(users):
        start_date = datetime.now() - timedelta(days=days)
        for day in range(days):
            date = start_date + timedelta(days=day)
            screen_time = np.random.normal(300, 50)  # in minutes
            notifications = np.random.poisson(50)
            productivity_app_usage = np.random.normal(60, 15)  # in minutes
            social_app_usage = np.random.normal(90, 20)  # in minutes
            entertainment_app_usage = np.random.normal(120, 30)  # in minutes
            data.append([user, date, screen_time, notifications, productivity_app_usage, social_app_usage, entertainment_app_usage])

    columns = ['user_id', 'date', 'screen_time', 'notifications', 'productivity_app_usage', 'social_app_usage', 'entertainment_app_usage']
    df = pd.DataFrame(data, columns=columns)
    return df

# Generate the detailed data
df = generate_detailed_synthetic_data()
print(df.head())

"""Data Preprocessing and Feature Engineering"""

# Data Preprocessing
# Handle missing values
df.fillna(df.mean(), inplace=True)

# Normalize the data
scaler = StandardScaler()
df[['screen_time', 'notifications', 'productivity_app_usage', 'social_app_usage', 'entertainment_app_usage']] = scaler.fit_transform(
    df[['screen_time', 'notifications', 'productivity_app_usage', 'social_app_usage', 'entertainment_app_usage']]
)

# Feature Engineering
df['day_of_week'] = df['date'].dt.dayofweek
df['weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)
df['hour_of_day'] = df['date'].dt.hour

print(df.head())

"""Model Building with Multiple Algorithms"""

from sklearn.cluster import AgglomerativeClustering, DBSCAN
from sklearn.decomposition import PCA

# Select features for clustering
features = ['screen_time', 'notifications', 'productivity_app_usage', 'social_app_usage', 'entertainment_app_usage', 'day_of_week', 'weekend']

# Reduce dimensionality for visualization
pca = PCA(n_components=2)
df_pca = pca.fit_transform(df[features])

# KMeans Clustering
kmeans = KMeans(n_clusters=3, random_state=42)
df['kmeans_cluster'] = kmeans.fit_predict(df[features])

# Agglomerative Clustering
agglo = AgglomerativeClustering(n_clusters=3)
df['agglo_cluster'] = agglo.fit_predict(df[features])

# DBSCAN Clustering
dbscan = DBSCAN(eps=0.5, min_samples=5)
df['dbscan_cluster'] = dbscan.fit_predict(df[features])

print(df[['user_id', 'kmeans_cluster', 'agglo_cluster', 'dbscan_cluster']].head())

""" Insights and Visualizations"""

# Visualize the clusters using PCA
plt.figure(figsize=(12, 6))

# KMeans
plt.subplot(1, 3, 1)
sns.scatterplot(x=df_pca[:, 0], y=df_pca[:, 1], hue=df['kmeans_cluster'], palette='viridis')
plt.title('KMeans Clusters')

# Agglomerative Clustering
plt.subplot(1, 3, 2)
sns.scatterplot(x=df_pca[:, 0], y=df_pca[:, 1], hue=df['agglo_cluster'], palette='viridis')
plt.title('Agglomerative Clusters')

# DBSCAN
plt.subplot(1, 3, 3)
sns.scatterplot(x=df_pca[:, 0], y=df_pca[:, 1], hue=df['dbscan_cluster'], palette='viridis')
plt.title('DBSCAN Clusters')

plt.tight_layout()
plt.show()

"""Recommendations System"""

# Enhanced Recommendations
def generate_detailed_recommendations(cluster, cluster_type):
    if cluster_type == 'kmeans':
        if cluster == 0:
            return "Consider reducing screen time during peak focus hours."
        elif cluster == 1:
            return "Try limiting notifications and social app usage."
        elif cluster == 2:
            return "Great focus! Maintain your current habits."
    elif cluster_type == 'agglo':
        # Similar recommendations for Agglomerative Clustering
        if cluster == 0:
            return "Consider balancing productivity and entertainment app usage."
        elif cluster == 1:
            return "Limit social app usage during work hours."
        elif cluster == 2:
            return "Maintain current usage habits for optimal focus."
    elif cluster_type == 'dbscan':
        # Similar recommendations for DBSCAN
        if cluster == 0:
            return "Consider a digital detox plan during weekends."
        elif cluster == 1:
            return "Optimize notifications to improve productivity."
        elif cluster == -1:  # Noise points
            return "Unusual usage patterns detected. Review your app usage."

df['kmeans_recommendations'] = df['kmeans_cluster'].apply(lambda x: generate_detailed_recommendations(x, 'kmeans'))
df['agglo_recommendations'] = df['agglo_cluster'].apply(lambda x: generate_detailed_recommendations(x, 'agglo'))
df['dbscan_recommendations'] = df['dbscan_cluster'].apply(lambda x: generate_detailed_recommendations(x, 'dbscan'))

print(df[['user_id', 'kmeans_recommendations', 'agglo_recommendations', 'dbscan_recommendations']].head())

"""User Interface (UI) for Interactivity"""

!pip install streamlit

# import streamlit as st

# # Streamlit App
# st.title("AttentionAI: Your Personal Attention Economy Analyst")

# st.sidebar.title("User Selection")
# user_id = st.sidebar.selectbox("Select User ID", df['user_id'].unique())

# user_data = df[df['user_id'] == user_id]

# st.subheader(f"Attention Data for User {user_id}")
# st.write(user_data)

# st.subheader("KMeans Recommendations")
# st.write(user_data['kmeans_recommendations'].values[0])

# st.subheader("Agglomerative Clustering Recommendations")
# st.write(user_data['agglo_recommendations'].values[0])

# st.subheader("DBSCAN Recommendations")
# st.write(user_data['dbscan_recommendations'].values[0])

# # Visualizations
# st.subheader("Screen Time vs. Notifications")
# fig, ax = plt.subplots()
# sns.scatterplot(x='screen_time', y='notifications', hue='kmeans_cluster', data=user_data, palette='viridis', ax=ax)
# st.pyplot(fig)

# !streamlit run app streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py

# !streamlit run digital_detox.py

# !pip install streamlit==1.25.0

# import streamlit as st
# import seaborn as sns

# st.set_page_config(page_title="AttentionAI", page_icon=":brain:", layout="wide")

# st.title("AttentionAI: Your Personal Attention Economy Analyst")
# st.markdown("### Track your digital behaviors and improve your focus.")

# # Display synthetic data
# st.sidebar.header("User Data")
# if st.sidebar.button("Generate New Data"):
#     df = generate_detailed_synthetic_data()

# st.sidebar.dataframe(df.head())

# # Cluster visualization
# st.subheader("Attention Clusters")
# fig, ax = plt.subplots()
# sns.scatterplot(x='screen_time', y='notifications', hue='cluster_type', data=df, palette='viridis', ax=ax)
# ax.set_title('Attention Clusters')
# st.pyplot(fig)

# # Recommendations
# st.subheader("Top Recommendations")
# recommendations = df[['user_id', 'attention_cluster', 'recommendations']].head(10)
# st.table(recommendations)

# # Download data
# st.sidebar.header("Download Data")
# csv = df.to_csv(index=False)
# b64 = base64.b64encode(csv.encode()).decode()  # some strings <-> bytes conversions necessary here
# href = f'<a href="data:file/csv;base64,{b64}" download="attention_data.csv">Download CSV File</a>'
# st.sidebar.markdown(href, unsafe_allow_html=True)

# # Custom CSS
# st.markdown(
#     """
#     <style>
#     .css-1d391kg {
#         background-color: #f0f0f0;
#         color: #333;
#     }
#     .css-145kmo2 {
#         background-color: #3498db;
#         color: #fff;
#         padding: 10px;
#         border-radius: 5px;
#     }
#     .css-145kmo2:hover {
#         background-color: #2980b9;
#     }
#     </style>
#     """,
#     unsafe_allow_html=True
# )

import streamlit as st
from datetime import datetime, timedelta
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN
import matplotlib.pyplot as plt
import seaborn as sns
import base64
import io

st.set_page_config(page_title="AttentionAI", page_icon=":brain:", layout="wide")

st.title("AttentionAI: Your Personal Attention Economy Analyst")
st.markdown("### Track your digital behaviors and improve your focus.")

# Display synthetic data
st.sidebar.header("User Data")
if st.sidebar.button("Generate New Data"):
    df = generate_detailed_synthetic_data()

st.sidebar.dataframe(df.head())

# Cluster visualization
st.subheader("Attention Clusters")
cluster_method = st.selectbox("Select Clustering Method", ["KMeans", "Agglomerative Clustering", "DBSCAN"])

if cluster_method == "KMeans":
    cluster_col = "kmeans_cluster"
    recommendation_col = "kmeans_recommendations"
elif cluster_method == "Agglomerative Clustering":
    cluster_col = "agglo_cluster"
    recommendation_col = "agglo_recommendations"
else:
    cluster_col = "dbscan_cluster"
    recommendation_col = "dbscan_recommendations"

fig, ax = plt.subplots()
sns.scatterplot(x='screen_time', y='notifications', hue=cluster_col, data=df, palette='viridis', ax=ax)
ax.set_title(f'Attention Clusters ({cluster_method})')
st.pyplot(fig)

# Recommendations
st.subheader("Top Recommendations")
recommendations = df[['user_id', cluster_col, recommendation_col]].head(10)
st.table(recommendations)

# Download data
st.sidebar.header("Download Data")
csv = df.to_csv(index=False)
b64 = base64.b64encode(csv.encode()).decode()  # some strings <-> bytes conversions necessary here
href = f'<a href="data:file/csv;base64,{b64}" download="attention_data.csv">Download CSV File</a>'
st.sidebar.markdown(href, unsafe_allow_html=True)

# Custom CSS
st.markdown(
    """
    <style>
    .css-1d391kg {
        background-color: #f0f0f0;
        color: #333;
    }
    .css-145kmo2 {
        background-color: #3498db;
        color: #fff;
        padding: 10px;
        border-radius: 5px;
    }
    .css-145kmo2:hover {
        background-color: #2980b9;
    }
    </style>
    """,
    unsafe_allow_html=True
)

